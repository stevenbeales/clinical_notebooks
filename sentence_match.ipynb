{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence match- different approachs\n",
    "### Tanzir Hasan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import difflib\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_sentence = \"Ovarian tumors of low malignant potential (borderline tumors)\"\n",
    "sentences = [\"Ovarian tumors of low malignant potential (borderline tumors)\",\n",
    "            \"ovarian tumors of low malignant potential (borderline tumors)\",\n",
    "            \"Ovarian tumors,  of low malignant potential (borderline tumors)\",\n",
    "            \"Ovarian tumors, that are of low malignant potential (borderline tumors)\", \n",
    "            \"Ovarian tumors that are of low malignant potential (borderline tumors)\",\n",
    "             \"Ovarian tumors that are of lowest malignant potential (borderline tumors)\",\n",
    "            \"Ovarian tumors of low malignant potential or borderline tumors\",\n",
    "            \"Borderline tumors is the  ovarian tumors of low malignant potential\",\n",
    "            \"Borderline tumors,ovarian tumors of low malignant potential \",\n",
    "            \"Patients suffering from breast tumors for 6 yers will be excluded\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'Ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(False, 'ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors,  of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors, that are of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors that are of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors that are of lowest malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors of low malignant potential or borderline tumors')\n",
      "(False, 'Borderline tumors is the  ovarian tumors of low malignant potential')\n",
      "(False, 'Borderline tumors,ovarian tumors of low malignant potential ')\n",
      "(False, 'Patients suffering from breast tumors for 6 yers will be excluded')\n"
     ]
    }
   ],
   "source": [
    "def is_exact_match(a,b):\n",
    "    \"\"\" Check if a and b are matches\"\"\"\n",
    "    return a== b\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(is_exact_match(target_sentence, sentence), sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Case_insensitive Token Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'Ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors,  of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors, that are of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors that are of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors that are of lowest malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors of low malignant potential or borderline tumors')\n",
      "(False, 'Borderline tumors is the  ovarian tumors of low malignant potential')\n",
      "(False, 'Borderline tumors,ovarian tumors of low malignant potential ')\n",
      "(False, 'Patients suffering from breast tumors for 6 yers will be excluded')\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "import nltk.tokenize\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "# Get default English stopwords and extend with punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(string.punctuation)\n",
    "stopwords.append('')\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def is_ci_token_match(a,b):\n",
    "    tokens_a =[token.lower().strip(string.punctuation) for token in tokenizer.tokenize(a)]\n",
    "    tokens_b =[token.lower().strip(string.punctuation) for token in tokenizer.tokenize(b)]\n",
    "    return (tokens_a == tokens_b)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print (is_ci_token_match(target_sentence, sentence), sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function word_tokenize in module nltk.tokenize:\n",
      "\n",
      "word_tokenize(text, language='english')\n",
      "    Return a tokenized copy of *text*,\n",
      "    using NLTK's recommended word tokenizer\n",
      "    (currently :class:`.TreebankWordTokenizer`\n",
      "    along with :class:`.PunktSentenceTokenizer`\n",
      "    for the specified language).\n",
      "    \n",
      "    :param text: text to split into sentences\n",
      "    :param language: the model name in the Punkt corpus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Case-Insensitive Token Match after Stopwording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'Ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors,  of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors, that are of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors that are of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors that are of lowest malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors of low malignant potential or borderline tumors')\n",
      "(False, 'Borderline tumors is the  ovarian tumors of low malignant potential')\n",
      "(False, 'Borderline tumors,ovarian tumors of low malignant potential ')\n",
      "(False, 'Patients suffering from breast tumors for 6 yers will be excluded')\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "import nltk.tokenize\n",
    "import string\n",
    "# Get default English stopwords and extende with punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(string.punctuation)\n",
    "stopwords.append('')\n",
    "\n",
    "# Create tokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def is_ci_token_stopword_match(a,b):\n",
    "    token_a =[token.lower().strip(string.punctuation) for token in tokenizer.tokenize(a) \\\n",
    "              if token.lower().strip(string.punctuation) not in stopwords]\n",
    "    token_b =[token.lower().strip(string.punctuation) for token in tokenizer.tokenize(b) \\\n",
    "              if token.lower().strip(string.punctuation) not in stopwords]\n",
    "    return (token_a == token_b)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print( is_ci_token_stopword_match(target_sentence,sentence), sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact token Match after stopwording and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'Ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors,  of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors, that are of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors that are of low malignant potential (borderline tumors)')\n",
      "(False, 'Ovarian tumors that are of lowest malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors of low malignant potential or borderline tumors')\n",
      "(False, 'Borderline tumors is the  ovarian tumors of low malignant potential')\n",
      "(False, 'Borderline tumors,ovarian tumors of low malignant potential ')\n",
      "(False, 'Patients suffering from breast tumors for 6 yers will be excluded')\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "import nltk.tokenize\n",
    "import string\n",
    "import nltk.stem.snowball\n",
    "\n",
    "# Get default English stopwords and extend with punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(string.punctuation)\n",
    "stopwords.append('')\n",
    "\n",
    "# Create tokenizer and stemmer\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "stemmer = nltk.stem.snowball.SnowballStemmer('english')\n",
    "\n",
    "def is_ci_token_stopword_stem_match(a,b):\n",
    "    token_a = [token.lower().strip(string.punctuation) for token in tokenizer.tokenize(a) \\\n",
    "               if token.lower().strip(string.punctuation) not in stopwords]\n",
    "    token_b = [token.lower().strip(string.punctuation) for token in tokenizer.tokenize(b) \\\n",
    "               if token.lower().strip(string.punctuation) not in stopwords]\n",
    "    stem_a = [stemmer.stem(token) for token in token_a]\n",
    "    stem_b = [stemmer.stem(token) for token in token_b]\n",
    "    return (stem_a == stem_b)\n",
    "for sentence in sentences:\n",
    "    print(is_ci_token_stopword_stem_match(target_sentence,sentence), sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact token Match after stopwording and Lementing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'Ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors,  of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors, that are of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors that are of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors that are of lowest malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors of low malignant potential or borderline tumors')\n",
      "(False, 'Borderline tumors is the  ovarian tumors of low malignant potential')\n",
      "(False, 'Borderline tumors,ovarian tumors of low malignant potential ')\n",
      "(False, 'Patients suffering from breast tumors for 6 yers will be excluded')\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "import nltk.tokenize\n",
    "import nltk.stem.snowball\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "\n",
    "# Get default English stopwords and extend with punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(string.punctuation)\n",
    "stopwords.append('')\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag[1].startswith('J'):\n",
    "        return(pos_tag[0], wordnet.ADJ)\n",
    "    elif pos_tag[1].startswith('V'):\n",
    "        return(pos_tag[0], wordnet.VERB)\n",
    "    elif pos_tag[1].startswith('N'):\n",
    "        return(pos_tag[0], wordnet.NOUN)\n",
    "    elif pos_tag[1].startswith('R'):\n",
    "        return(pos_tag[0],wordnet.ADV)\n",
    "    else:\n",
    "        return( pos_tag[0],wordnet.NOUN)\n",
    "    \n",
    "# Create tokenizer and lemmantizer\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "lemmantizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def is_ci_token_stopword_lemma_match(a,b):\n",
    "    pos_a = map(get_wordnet_pos,nltk.pos_tag(tokenizer.tokenize(a)))\n",
    "    pos_b = map(get_wordnet_pos,nltk.pos_tag(tokenizer.tokenize(b)))\n",
    "    lemmae_a = [lemmantizer.lemmatize(token.lower().strip(string.punctuation),pos) for token,pos in pos_a\\\n",
    "               if token.lower().strip(string.punctuation) not in stopwords]\n",
    "    lemmae_b = [lemmantizer.lemmatize(token.lower().strip(string.punctuation),pos) for token,pos in pos_b\\\n",
    "               if token.lower().strip(string.punctuation) not in stopwords]\n",
    "    return(lemmae_a == lemmae_b)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(is_ci_token_stopword_lemma_match(target_sentence, sentence), sentence)\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Partial Sequence Match after Stopwording and Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'Ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors,  of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors, that are of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors that are of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors that are of lowest malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors of low malignant potential or borderline tumors')\n",
      "(True, 'Borderline tumors is the  ovarian tumors of low malignant potential')\n",
      "(True, 'Borderline tumors,ovarian tumors of low malignant potential ')\n",
      "(True, 'Patients suffering from breast tumors for 6 yers will be excluded')\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "import nltk.tokenize\n",
    "import nltk.stem.snowball\n",
    "import string\n",
    "from nltk.corpus import wordnet\n",
    "# Get default English stopwords and extend with punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(string.punctuation)\n",
    "stopwords.append('')\n",
    "\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag[1].startswith('J'):\n",
    "        return (pos_tag[0], wordnet.ADJ)\n",
    "    elif pos_tag[1].startswith('V'):\n",
    "        return(pos_tag[0], wordnet.VERB)\n",
    "    elif pos_tag[1].startswith('N'):\n",
    "        return(pos_tag[0], wordnet.NOUN)\n",
    "    elif pos_tag[1].startswith('R'):\n",
    "        return(pos_tag[0], wordnet.ADV)\n",
    "    else:\n",
    "        return(pos_tag[0], wordnet.NOUN)\n",
    "\n",
    "# Create tokenizer and lemmatizer\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def is_ci_partial_seq_tken_stopword_lemma_match(a,b):\n",
    "    pos_a = map(get_wordnet_pos, nltk.pos_tag(tokenizer.tokenize(a)))\n",
    "    pos_b = map(get_wordnet_pos, nltk.pos_tag(tokenizer.tokenize(b)))\n",
    "    lemmae_a = [lemmatizer.lemmatize(token.lower().strip(string.punctuation),pos) for token, pos in pos_a \\\n",
    "               if token.lower().strip(string.punctuation) not in stopwords]\n",
    "    lemmae_b = [lemmatizer.lemmatize(token.lower().strip(string.punctuation),pos) for token,pos in pos_a \\\n",
    "               if token.lower().strip(string.punctuation) not in stopwords]\n",
    "    # Create sequence matcher\n",
    "    s = difflib.SequenceMatcher(None, lemmae_a, lemmae_b)\n",
    "    return(s.ratio() > 0.66)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(is_ci_partial_seq_tken_stopword_lemma_match(target_sentence, sentence), sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Noun set Match after stopword and lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'Ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'ovarian tumors of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors,  of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors, that are of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors that are of low malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors that are of lowest malignant potential (borderline tumors)')\n",
      "(True, 'Ovarian tumors of low malignant potential or borderline tumors')\n",
      "(True, 'Borderline tumors is the  ovarian tumors of low malignant potential')\n",
      "(True, 'Borderline tumors,ovarian tumors of low malignant potential ')\n",
      "(False, 'Patients suffering from breast tumors for 6 yers will be excluded')\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "import nltk.tokenize\n",
    "import nltk.stem.snowball\n",
    "import string\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "## Get English stopwords  and extend with puctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(string.punctuation)\n",
    "stopwords.append('')\n",
    "\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag[1].startswith('J'):\n",
    "        return(pos_tag[0],wordnet.ADJ)\n",
    "    elif pos_tag[1].startswith('V'):\n",
    "        return(pos_tag[0],wordnet.VERB)\n",
    "    elif pos_tag[1].startswith('N'):\n",
    "        return(pos_tag[0],wordnet.NOUN)\n",
    "    elif pos_tag[1].startswith('R'):\n",
    "        return(pos_tag[0], wordnet.ADV)\n",
    "    else:\n",
    "        return(pos_tag[0],wordnet.NOUN)\n",
    "    \n",
    "    \n",
    "# create tokenizer and lemmatizer\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def is_ci_partial_set_token_stopword_lemma_match(a,b):\n",
    "    pos_a = map(get_wordnet_pos,nltk.pos_tag(tokenizer.tokenize(a)))\n",
    "    pos_b = map(get_wordnet_pos, nltk.pos_tag(tokenizer.tokenize(b)))\n",
    "    lemmae_a = [lemmatizer.lemmatize(token.lower().strip(string.punctuation),pos) for token, pos in pos_a\\\n",
    "                if pos == wordnet.NOUN and token.lower().strip(string.punctuation) not in stopwords]\n",
    "    lemmae_b = [lemmatizer.lemmatize(token.lower().strip(string.punctuation),pos) for token, pos in pos_b\\\n",
    "                if pos == wordnet.NOUN and token.lower().strip(string.punctuation) not in stopwords]\n",
    "    # Calculate Jaccard similarity \n",
    "    ratio = len(set(lemmae_a).intersection(lemmae_b))/ float(len(set(lemmae_a).union(lemmae_b)))\n",
    "    return(ratio > 0.66)\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(is_ci_partial_set_token_stopword_lemma_match(target_sentence, sentence),sentence) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
